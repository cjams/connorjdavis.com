"""
FastAPI Blog Backend
Generated by WordPress Migration Tool
Enhanced with MDX support
"""

from fastapi import FastAPI, HTTPException
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from pathlib import Path
import json
import frontmatter
from typing import List, Optional, Dict, Any
import threading
import time
import os
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

from app.mdx_processor import MDXProcessor
from app.index_generator import IndexGenerator

app = FastAPI(title="Blog API", version="2.0.0")

# Detect if we're in debug/development mode
def is_debug_mode():
    """
    Detect if the app is running in debug/development mode.
    Returns True for 'fastapi dev' and False for 'fastapi run'
    """
    # Check if we're running with reload (fastapi dev uses --reload)
    if hasattr(app, 'debug') and app.debug:
        return True
    
    # Check environment variables
    if os.getenv('FASTAPI_ENV') == 'development':
        return True
        
    # Check if uvicorn is running with reload
    import sys
    if '--reload' in sys.argv:
        return True
        
    # Check for common development indicators
    if os.getenv('DEBUG') == 'true' or os.getenv('DEBUG') == '1':
        return True
        
    # Default to production mode for safety
    return False

DEBUG_MODE = is_debug_mode()
print(f"üîß Running in {'DEBUG' if DEBUG_MODE else 'PRODUCTION'} mode")
if DEBUG_MODE:
    print("   ‚Üí Serving both draft and published content")
else:
    print("   ‚Üí Serving only published content")

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:3001", "http://localhost:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Mount static files
app.mount("/static", StaticFiles(directory="static"), name="static")
# Mount media files directly for MDX image references
app.mount("/media", StaticFiles(directory="static/media"), name="media")

# Initialize MDX processor
content_dir = Path("content")
mdx_processor = MDXProcessor(content_dir)

# Initialize index generator
index_generator = IndexGenerator(content_dir)

# File watcher for automatic index regeneration
class ContentFileHandler(FileSystemEventHandler):
    def __init__(self):
        super().__init__()
        self._last_regenerate = 0
        self._regenerate_delay = 1  # seconds
    
    def on_modified(self, event):
        if event.is_directory:
            return
        
        # Only handle MDX files
        if event.src_path.endswith('.mdx'):
            self._schedule_regenerate(event.src_path)
    
    def on_created(self, event):
        if event.is_directory:
            return
        
        if event.src_path.endswith('.mdx'):
            self._schedule_regenerate(event.src_path)
    
    def on_deleted(self, event):
        if event.is_directory:
            return
        
        if event.src_path.endswith('.mdx'):
            self._schedule_regenerate(event.src_path)
    
    def _schedule_regenerate(self, file_path: str = None):
        """Schedule index regeneration with debouncing"""
        current_time = time.time()
        if current_time - self._last_regenerate > self._regenerate_delay:
            self._last_regenerate = current_time
            # Use a separate thread to avoid blocking the file watcher
            threading.Thread(target=self._regenerate_index, args=(file_path,), daemon=True).start()
    
    def _regenerate_index(self, file_path: str = None):
        """Regenerate the content index and update metadata if needed"""
        try:
            print("üîÑ Detected MDX file changes, processing...")
            
            # Update metadata for the specific file if it was modified (not deleted)
            if file_path and Path(file_path).exists():
                filepath = Path(file_path)
                if filepath.suffix == '.mdx':
                    print(f"üìÑ Updating metadata for {filepath.name}...")
                    mdx_processor.update_post_metadata(filepath)
            
            # Regenerate the index
            index_generator.generate_and_save()
            print("‚úÖ Content processing completed successfully")
        except Exception as e:
            print(f"‚ùå Error processing content changes: {e}")

# Global file watcher observer
observer = None

@app.on_event("startup")
async def startup_event():
    """Initialize file watcher on startup"""
    global observer
    
    # Generate initial index
    try:
        print("üöÄ Generating initial content index...")
        index_generator.generate_and_save()
    except Exception as e:
        print(f"Warning: Could not generate initial index: {e}")
    
    # Only start file watcher in debug/development mode
    if DEBUG_MODE:
        try:
            observer = Observer()
            event_handler = ContentFileHandler()
            
            # Watch both posts and pages directories
            posts_dir = content_dir / "posts"
            pages_dir = content_dir / "pages"
            
            if posts_dir.exists():
                observer.schedule(event_handler, str(posts_dir), recursive=False)
                print(f"üìÅ Watching {posts_dir} for MDX changes...")
            
            if pages_dir.exists():
                observer.schedule(event_handler, str(pages_dir), recursive=False)
                print(f"üìÅ Watching {pages_dir} for MDX changes...")
            
            observer.start()
            print("üëÄ File watcher started successfully")
            
        except Exception as e:
            print(f"Warning: Could not start file watcher: {e}")
    else:
        print("üì¥ File watching disabled in production mode")

@app.on_event("shutdown")
async def shutdown_event():
    """Stop file watcher on shutdown"""
    global observer
    if observer:
        observer.stop()
        observer.join()
        print("üõë File watcher stopped")

# Load content index
def load_content_index():
    index_file = Path("content/index.json")
    if index_file.exists():
        with open(index_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {"posts": [], "pages": [], "tags": []}

def load_post_content(filename: str, content_type: str = "posts"):
    """Load the full content of a post or page"""
    content_dir_path = Path(f"content/{content_type}")
    file_path = content_dir_path / filename
    
    if not file_path.exists():
        return None
    
    # Check if it's an MDX file
    if file_path.suffix == '.mdx':
        return mdx_processor.load_mdx_file(file_path)
    
    # Fallback to regular markdown
    with open(file_path, 'r', encoding='utf-8') as f:
        post_obj = frontmatter.load(f)
    
    return {
        'metadata': post_obj.metadata,
        'content': post_obj.content,
        'components': [],
        'toc': '',
        'raw_content': post_obj.content
    }

@app.get("/")
async def root():
    return {"message": "Blog API is running"}

@app.get("/posts")
async def get_posts(page: Optional[int] = 1, per_page: Optional[int] = 10, limit: Optional[int] = None, tag: Optional[str] = None):
    """Get all posts with optional filtering and pagination"""
    index = load_content_index()
    posts = index['posts']
    
    # Filter by status: only show published posts in production mode
    if not DEBUG_MODE:
        posts = [p for p in posts if p.get('status', 'publish') == 'publish']
    
    # Filter by tag
    if tag:
        posts = [p for p in posts if tag in p.get('tags', [])]
    
    # Calculate total before pagination
    total = len(posts)
    
    # Handle legacy limit parameter (for backwards compatibility)
    if limit:
        posts = posts[:limit]
        return posts
    
    # Calculate pagination
    total_pages = (total + per_page - 1) // per_page  # Ceiling division
    start_idx = (page - 1) * per_page
    end_idx = start_idx + per_page
    
    # Apply pagination
    paginated_posts = posts[start_idx:end_idx]
    
    return {
        "posts": paginated_posts,
        "total": total,
        "page": page,
        "per_page": per_page,
        "total_pages": total_pages
    }

@app.get("/posts/{slug}")
async def get_post(slug: str):
    """Get a specific post by slug"""
    index = load_content_index()
    
    # Find post in index
    post_meta = None
    for post in index['posts']:
        if post.get('slug') == slug:
            post_meta = post
            break
    
    if not post_meta:
        raise HTTPException(status_code=404, detail="Post not found")
    
    # In production mode, only serve published posts
    if not DEBUG_MODE and post_meta.get('status', 'publish') != 'publish':
        raise HTTPException(status_code=404, detail="Post not found")
    
    # Load full content
    post_content = load_post_content(post_meta['filename'])
    if not post_content:
        raise HTTPException(status_code=404, detail="Post content not found")
    
    return {
        **post_meta,
        'content': post_content['content'],
        'components': post_content.get('components', []),
        'toc': post_content.get('toc', ''),
        'full_metadata': post_content['metadata']
    }

@app.get("/pages/{slug}")
async def get_page(slug: str):
    """Get a specific page by slug"""
    index = load_content_index()
    
    # Find page in index
    page_meta = None
    for page in index['pages']:
        if page.get('slug') == slug:
            page_meta = page
            break
    
    if not page_meta:
        raise HTTPException(status_code=404, detail="Page not found")
    
    # Load full content
    page_content = load_post_content(page_meta['filename'], 'pages')
    if not page_content:
        raise HTTPException(status_code=404, detail="Page content not found")
    
    return {
        **page_meta,
        'content': page_content['content'],
        'full_metadata': page_content['metadata']
    }

@app.get("/tags")
async def get_tags():
    """Get all tags"""
    index = load_content_index()
    return index['tags']

@app.get("/stats")
async def get_stats():
    """Get blog statistics"""
    index = load_content_index()
    return {
        'total_posts': len(index['posts']),
        'total_pages': len(index['pages']),
        'total_tags': len(index['tags']),
        'last_updated': index.get('generated_at')
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000, reload=True)
